{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP: LDA & Sentiment Analysis on Movie Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pickled files/models? (y/n, defaults to y): y\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "use_pickled = input(\"Load pickled files/models? (y/n, defaults to y): \")\n",
    "if use_pickled == 'n':\n",
    "    use_pickled = False\n",
    "else:\n",
    "    use_pickled = True\n",
    "\n",
    "pickled_dir = \"pickled\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('IMDB-Dataset.csv', error_bad_lines=False);\n",
    "\n",
    "# split positive and negative sentiment reviews\n",
    "pos_reviews = data[data.sentiment == \"positive\"]\n",
    "neg_reviews = data[data.sentiment == \"negative\"]\n",
    "\n",
    "pos_data = pos_reviews[['review']]\n",
    "pos_data['index'] = pos_data.index\n",
    "pos_documents = pos_data\n",
    "\n",
    "neg_data = neg_reviews[['review']]\n",
    "neg_data['index'] = neg_data.index\n",
    "neg_documents = neg_data\n",
    "\n",
    "\n",
    "# from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# stop_words = list(set(stopwords.words('english')))\n",
    "\n",
    "'''Positive Data'''\n",
    "# Remove punctuation using regular expresssion\n",
    "pos_documents['review_processed'] = pos_documents['review'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "# Lowercase the words using regular expresssion\n",
    "pos_documents['review_processed'] = pos_documents['review'].map(lambda x: x.lower())\n",
    "'''Negative Data'''\n",
    "# Remove punctuation using regular expresssion\n",
    "neg_documents['review_processed'] = neg_documents['review'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "# Lowercase the words using regular expresssion\n",
    "neg_documents['review_processed'] = neg_documents['review'].map(lambda x: x.lower())\n",
    "\n",
    "## Stemming and Lematizing\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n",
    "\n",
    "pos_proc_docs_fname = os.path.join(pickled_dir, \"pos_processed_docs\")\n",
    "neg_proc_docs_fname = os.path.join(pickled_dir, \"neg_processed_docs\")\n",
    "if use_pickled:\n",
    "    with open(pos_proc_docs_fname, 'rb') as f1:\n",
    "        pos_processed_documents = pickle.load(f1)\n",
    "    with open(neg_proc_docs_fname, 'rb') as f2:\n",
    "        neg_processed_documents = pickle.load(f2)\n",
    "else:\n",
    "    pos_processed_documents = pos_documents['review_processed'].map(preprocess)\n",
    "    neg_processed_documents = neg_documents['review_processed'].map(preprocess)\n",
    "    with open(pos_proc_docs_fname, 'wb+') as f1:\n",
    "        pickle.dump(pos_processed_documents, f1)\n",
    "    with open(neg_proc_docs_fname, 'wb+') as f2:\n",
    "        pickle.dump(neg_processed_documents, f2)\n",
    "        \n",
    "import gensim\n",
    "\n",
    "# Making Positive and Negative Dictionaries\n",
    "pos_dictionary = gensim.corpora.Dictionary(pos_processed_documents)\n",
    "neg_dictionary = gensim.corpora.Dictionary(neg_processed_documents)        \n",
    "#Removing Extreme Cases of Words\n",
    "pos_dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "pos_bow_corpus = [pos_dictionary.doc2bow(doc) for doc in pos_processed_documents] # corpus for topics that are seen as positive\n",
    "\n",
    "neg_dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "neg_bow_corpus = [neg_dictionary.doc2bow(doc) for doc in neg_processed_documents] # corpus for topics that are seen as negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the LDA Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics to generate: 300\n"
     ]
    }
   ],
   "source": [
    "num_topics = int(input(\"Number of topics to generate: \"))\n",
    "\n",
    "pos_lda_model_fname = os.path.join(pickled_dir, 'pos_lda_model_{}_topics'.format(num_topics))\n",
    "neg_lda_model_fname = os.path.join(pickled_dir, 'neg_lda_model_{}_topics'.format(num_topics))\n",
    "if use_pickled:\n",
    "    pos_lda_model = gensim.models.LdaMulticore.load(pos_lda_model_fname)\n",
    "    neg_lda_model = gensim.models.LdaMulticore.load(neg_lda_model_fname)\n",
    "\n",
    "else:\n",
    "    pos_lda_model = gensim.models.LdaMulticore(\n",
    "        corpus=pos_bow_corpus, \n",
    "        num_topics=num_topics, \n",
    "        id2word=pos_dictionary, \n",
    "        passes=2, \n",
    "        workers=2)\n",
    "\n",
    "    neg_lda_model = gensim.models.LdaMulticore(\n",
    "        corpus=neg_bow_corpus, \n",
    "        num_topics=num_topics, \n",
    "        id2word=neg_dictionary, \n",
    "        passes=2, \n",
    "        workers=2)\n",
    "    \n",
    "    pos_lda_model.save(pos_lda_model_fname)\n",
    "    neg_lda_model.save(neg_lda_model_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "# Visualize positive topic words\n",
    "pyLDAvis.enable_notebook()\n",
    "pos_vis = pyLDAvis.gensim.prepare(pos_lda_model, pos_bow_corpus, pos_dictionary, sort_topics=False)\n",
    "pos_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize negative topic words\n",
    "pyLDAvis.enable_notebook()\n",
    "neg_vis = pyLDAvis.gensim.prepare(neg_lda_model, neg_bow_corpus, neg_dictionary, sort_topics=False)\n",
    "neg_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic(text):\n",
    "    bow_vector = pos_dictionary.doc2bow(preprocess(text))\n",
    "    for idx, score in sorted(pos_lda_model[bow_vector], key=lambda tup:-1*tup[1]):\n",
    "        pos_score = score\n",
    "        pos_topic = \"Topic: {}\\nWords: {}\".format(idx+1, pos_lda_model.print_topic(idx, 15))\n",
    "        break           \n",
    "    \n",
    "    bow_vector = neg_dictionary.doc2bow(preprocess(text))\n",
    "    for idx, score in sorted(neg_lda_model[bow_vector], key=lambda tup:-1*tup[1]):\n",
    "        neg_score = score\n",
    "        neg_topic = \"Topic: {}\\nWords: {}\".format(idx+1, neg_lda_model.print_topic(idx, 15))\n",
    "        break\n",
    "        \n",
    "    if pos_score>neg_score:\n",
    "        return pos_topic\n",
    "    else:\n",
    "        return neg_topic\n",
    "    \n",
    "    \n",
    "def get_mult_topics(text):\n",
    "    bow_vector = pos_dictionary.doc2bow(preprocess(text))\n",
    "    bow_vector = neg_dictionary.doc2bow(preprocess(text))\n",
    "    \n",
    "    print(\"\\nPositive Topics:\")\n",
    "    for idx, score in sorted(pos_lda_model[bow_vector], key=lambda tup:-1*tup[1]):    \n",
    "        print('Topic: {} Score: {}\\nWords: {}'.format(idx+1, score, pos_lda_model.print_topic(idx, 15)))\n",
    "        \n",
    "    print(\"\\nNegative Topics:\")\n",
    "    for idx, score in sorted(neg_lda_model[bow_vector], key=lambda tup:-1*tup[1]):    \n",
    "        print('Topic: {} Score: {}\\nWords: {}'.format(idx+1, score, neg_lda_model.print_topic(idx, 15)))\n",
    "\n",
    "\n",
    "def get_sentiment(text):\n",
    "    pos_score = 0\n",
    "    neg_score = 0\n",
    "    \n",
    "    #get what positive topics might be related\n",
    "    bow_vector = pos_dictionary.doc2bow(preprocess(text))\n",
    "    count = 0\n",
    "    for idx, score in sorted(pos_lda_model[bow_vector], key=lambda tup:-1*tup[1]):\n",
    "        pos_score += score\n",
    "        count += 1\n",
    "        if count is 3:\n",
    "            pos_score = pos_score/3\n",
    "            break\n",
    "    \n",
    "    #get what negative topics might be related\n",
    "    bow_vector = neg_dictionary.doc2bow(preprocess(text))\n",
    "    count = 0\n",
    "    for idx, score in sorted(neg_lda_model[bow_vector], key=lambda tup:-1*tup[1]):    \n",
    "        neg_score += score\n",
    "        count += 1\n",
    "        if count is 3:\n",
    "            neg_score = neg_score/3\n",
    "            break\n",
    "            \n",
    "    if pos_score>neg_score:\n",
    "        print(\"We predict that opinions on this movie are generally positive.\")\n",
    "        result = neg_score/pos_score\n",
    "        result = 100 - (30*result)\n",
    "        return result\n",
    "    else:\n",
    "        print(\"We predict that opinions on this movie are generally negative.\")\n",
    "        result = pos_score/neg_score\n",
    "        result *= 60\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a movie description to analyze:A young Bruce Wayne (Christian Bale) travels to the Far East, where he's trained in the martial arts by Henri Ducard (Liam Neeson), a member of the mysterious League of Shadows. When Ducard reveals the League's true purpose -- the complete destruction of Gotham City -- Wayne returns to Gotham intent on cleaning up the city without resorting to murder. With the help of Alfred (Michael Caine), his loyal butler, and Lucius Fox (Morgan Freeman), a tech expert at Wayne Enterprises, Batman is born.\n",
      "\n",
      "We predict that opinions on this movie are generally positive.\n",
      "\n",
      "We predict that this movie relates to the following topic:\n",
      "Topic: 163\n",
      "Words: 0.045*\"batman\" + 0.026*\"burton\" + 0.019*\"return\" + 0.019*\"buffalo\" + 0.017*\"charact\" + 0.013*\"penguin\" + 0.011*\"dark\" + 0.011*\"like\" + 0.010*\"villain\" + 0.010*\"interest\" + 0.009*\"plot\" + 0.008*\"flaw\" + 0.008*\"problem\" + 0.008*\"stori\" + 0.008*\"taylor\"\n",
      "\n",
      "We predict that this movie has a rating of ~75.711%.\n"
     ]
    }
   ],
   "source": [
    "unseen_movie_description = input(\"Please enter a movie description to analyze:\")\n",
    "print()\n",
    "result = round(get_sentiment(unseen_movie_description), 3)\n",
    "#print(\"\\nWe predict that opinions on this movie are generally {}.\".format(get_general_sentiment(unseen_movie_description)))\n",
    "print(\"\\nWe predict that this movie relates to the following topic:\\n{}\".format(get_topic(unseen_movie_description)))\n",
    "#print(\"\\nWe predict that this movie relates to the following topics:\")\n",
    "#get_mult_topics(unseen_movie_description)\n",
    "print(\"\\nWe predict that this movie has a rating of ~{}%.\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
