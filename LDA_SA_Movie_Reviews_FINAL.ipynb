{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP: LDA & Sentiment Analysis on Movie Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "use_pickled = input(\"Load pickled files/models? (y/n, defaults to y): \")\n",
    "if use_pickled == 'n':\n",
    "    use_pickled = False\n",
    "else:\n",
    "    use_pickled = True\n",
    "\n",
    "pickled_dir = \"pickled\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('IMDB-Dataset.csv', error_bad_lines=False);\n",
    "\n",
    "# split positive and negative sentiment reviews\n",
    "pos_reviews = data[data.sentiment == \"positive\"]\n",
    "neg_reviews = data[data.sentiment == \"negative\"]\n",
    "\n",
    "pos_data = pos_reviews[['review']]\n",
    "pos_data['index'] = pos_data.index\n",
    "pos_documents = pos_data\n",
    "\n",
    "neg_data = neg_reviews[['review']]\n",
    "neg_data['index'] = neg_data.index\n",
    "neg_documents = neg_data\n",
    "\n",
    "\n",
    "# from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# stop_words = list(set(stopwords.words('english')))\n",
    "\n",
    "'''Positive Data'''\n",
    "# Remove punctuation using regular expresssion\n",
    "pos_documents['review_processed'] = pos_documents['review'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "# Lowercase the words using regular expresssion\n",
    "pos_documents['review_processed'] = pos_documents['review'].map(lambda x: x.lower())\n",
    "'''Negative Data'''\n",
    "# Remove punctuation using regular expresssion\n",
    "neg_documents['review_processed'] = neg_documents['review'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "# Lowercase the words using regular expresssion\n",
    "neg_documents['review_processed'] = neg_documents['review'].map(lambda x: x.lower())\n",
    "\n",
    "## Stemming and Lematizing\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n",
    "\n",
    "pos_proc_docs_fname = os.path.join(pickled_dir, \"pos_processed_docs\")\n",
    "neg_proc_docs_fname = os.path.join(pickled_dir, \"neg_processed_docs\")\n",
    "if use_pickled:\n",
    "    with open(pos_proc_docs_fname, 'rb') as f1:\n",
    "        pos_processed_documents = pickle.load(f1)\n",
    "    with open(neg_proc_docs_fname, 'rb') as f2:\n",
    "        neg_processed_documents = pickle.load(f2)\n",
    "else:\n",
    "    pos_processed_documents = pos_documents['review_processed'].map(preprocess)\n",
    "    neg_processed_documents = neg_documents['review_processed'].map(preprocess)\n",
    "    with open(pos_proc_docs_fname, 'wb+') as f1:\n",
    "        pickle.dump(pos_processed_documents, f1)\n",
    "    with open(neg_proc_docs_fname, 'wb+') as f2:\n",
    "        pickle.dump(neg_processed_documents, f2)\n",
    "        \n",
    "import gensim\n",
    "\n",
    "# Making Positive and Negative Dictionaries\n",
    "pos_dictionary = gensim.corpora.Dictionary(pos_processed_documents)\n",
    "neg_dictionary = gensim.corpora.Dictionary(neg_processed_documents)        \n",
    "#Removing Extreme Cases of Words\n",
    "pos_dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "pos_bow_corpus = [pos_dictionary.doc2bow(doc) for doc in pos_processed_documents] # corpus for topics that are seen as positive\n",
    "\n",
    "neg_dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "neg_bow_corpus = [neg_dictionary.doc2bow(doc) for doc in neg_processed_documents] # corpus for topics that are seen as negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the LDA Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics to generate: 300\n"
     ]
    }
   ],
   "source": [
    "num_topics = int(input(\"Number of topics to generate: \"))\n",
    "\n",
    "pos_lda_model_fname = os.path.join(pickled_dir, 'pos_lda_model_{}_topics'.format(num_topics))\n",
    "neg_lda_model_fname = os.path.join(pickled_dir, 'neg_lda_model_{}_topics'.format(num_topics))\n",
    "if use_pickled:\n",
    "    pos_lda_model = gensim.models.LdaMulticore.load(pos_lda_model_fname)\n",
    "    neg_lda_model = gensim.models.LdaMulticore.load(neg_lda_model_fname)\n",
    "\n",
    "else:\n",
    "    pos_lda_model = gensim.models.LdaMulticore(\n",
    "        corpus=pos_bow_corpus, \n",
    "        num_topics=num_topics, \n",
    "        id2word=pos_dictionary, \n",
    "        passes=2, \n",
    "        workers=2)\n",
    "\n",
    "    neg_lda_model = gensim.models.LdaMulticore(\n",
    "        corpus=neg_bow_corpus, \n",
    "        num_topics=num_topics, \n",
    "        id2word=neg_dictionary, \n",
    "        passes=2, \n",
    "        workers=2)\n",
    "    \n",
    "    pos_lda_model.save(pos_lda_model_fname)\n",
    "    neg_lda_model.save(neg_lda_model_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "# Visualize positive topic words\n",
    "pyLDAvis.enable_notebook()\n",
    "pos_vis = pyLDAvis.gensim.prepare(pos_lda_model, pos_bow_corpus, pos_dictionary, sort_topics=False)\n",
    "pos_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize negative topic words\n",
    "pyLDAvis.enable_notebook()\n",
    "neg_vis = pyLDAvis.gensim.prepare(neg_lda_model, neg_bow_corpus, neg_dictionary, sort_topics=False)\n",
    "neg_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic(text):\n",
    "    bow_vector = pos_dictionary.doc2bow(preprocess(text))\n",
    "    for idx, score in sorted(pos_lda_model[bow_vector], key=lambda tup:-1*tup[1]):\n",
    "        pos_score = score\n",
    "        pos_topic = \"Topic: {}\\nWords: {}\".format(idx+1, pos_lda_model.print_topic(idx, 15))\n",
    "        break           \n",
    "    \n",
    "    bow_vector = neg_dictionary.doc2bow(preprocess(text))\n",
    "    for idx, score in sorted(neg_lda_model[bow_vector], key=lambda tup:-1*tup[1]):\n",
    "        neg_score = score\n",
    "        neg_topic = \"Topic: {}\\nWords: {}\".format(idx+1, neg_lda_model.print_topic(idx, 15))\n",
    "        break\n",
    "        \n",
    "    if pos_score>neg_score:\n",
    "        return pos_topic\n",
    "    else:\n",
    "        return neg_topic\n",
    "    \n",
    "    \n",
    "def get_mult_topics(text):\n",
    "    bow_vector = pos_dictionary.doc2bow(preprocess(text))\n",
    "    bow_vector = neg_dictionary.doc2bow(preprocess(text))\n",
    "    \n",
    "    print(\"\\nPositive Topics:\")\n",
    "    for idx, score in sorted(pos_lda_model[bow_vector], key=lambda tup:-1*tup[1]):    \n",
    "        print('Topic: {} Score: {}\\nWords: {}'.format(idx+1, score, pos_lda_model.print_topic(idx, 15)))\n",
    "        \n",
    "    print(\"\\nNegative Topics:\")\n",
    "    for idx, score in sorted(neg_lda_model[bow_vector], key=lambda tup:-1*tup[1]):    \n",
    "        print('Topic: {} Score: {}\\nWords: {}'.format(idx+1, score, neg_lda_model.print_topic(idx, 15)))\n",
    "    \n",
    "\n",
    "def get_sentiment(text):\n",
    "    #get what positive topics might be related\n",
    "    bow_vector = pos_dictionary.doc2bow(preprocess(text))\n",
    "    for idx, score in sorted(pos_lda_model[bow_vector], key=lambda tup:-1*tup[1]):\n",
    "        pos_score = score\n",
    "        break\n",
    "    \n",
    "    #get what negative topics might be related\n",
    "    bow_vector = neg_dictionary.doc2bow(preprocess(text))\n",
    "    for idx, score in sorted(neg_lda_model[bow_vector], key=lambda tup:-1*tup[1]):    \n",
    "        neg_score = score\n",
    "        break\n",
    "    \n",
    "    if pos_score>neg_score:\n",
    "        result = neg_score/pos_score\n",
    "        result = 100 - (30*result)\n",
    "        return result\n",
    "    else:\n",
    "        result = pos_score/neg_score\n",
    "        result *= 60\n",
    "        return result\n",
    "    \n",
    "    \n",
    "def get_general_sentiment(text):\n",
    "    #get what positive topics might be related\n",
    "    bow_vector = pos_dictionary.doc2bow(preprocess(text))\n",
    "    for idx, score in sorted(pos_lda_model[bow_vector], key=lambda tup:-1*tup[1]):\n",
    "        pos_score = score\n",
    "        break\n",
    "\n",
    "    #get what negative topics might be related\n",
    "    bow_vector = neg_dictionary.doc2bow(preprocess(text))\n",
    "    for idx, score in sorted(neg_lda_model[bow_vector], key=lambda tup:-1*tup[1]):    \n",
    "        neg_score = score\n",
    "        break\n",
    "        \n",
    "    if pos_score>neg_score:\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        return \"negative\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a movie description to analyze: Johnny is a successful banker who lives happily in a San Francisco townhouse with his fianc√©e, Lisa. One day, inexplicably, she gets bored of him and decides to seduce Johnny's best friend, Mark. From there, nothing will be the same again.\n",
      "\n",
      "We predict that opinions on this movie are generally negative.\n",
      "\n",
      "We predict that this movie relates to the following topic:\n",
      "Topic: 184\n",
      "Words: 0.021*\"peter\" + 0.016*\"time\" + 0.014*\"falk\" + 0.014*\"bergman\" + 0.014*\"father\" + 0.012*\"work\" + 0.011*\"great\" + 0.011*\"be\" + 0.008*\"main\" + 0.008*\"stori\" + 0.008*\"friend\" + 0.008*\"stefan\" + 0.008*\"tell\" + 0.008*\"german\" + 0.007*\"afterward\"\n",
      "\n",
      "We predict that this movie has a rating of ~42.49%.\n"
     ]
    }
   ],
   "source": [
    "unseen_movie_description = input(\"Please enter a movie description to analyze: \")\n",
    "result = round(get_sentiment(unseen_movie_description), 3)\n",
    "print(\"\\nWe predict that opinions on this movie are generally {}.\".format(get_general_sentiment(unseen_movie_description)))\n",
    "print(\"\\nWe predict that this movie relates to the following topic:\\n{}\".format(get_topic(unseen_movie_description)))\n",
    "#print(\"\\nWe predict that this movie relates to the following topics:\")\n",
    "#get_mult_topics(unseen_movie_description)\n",
    "print(\"\\nWe predict that this movie has a rating of ~{}%.\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
